
# Rock, Paper, and Scissors Image Classification
This is a final project for Dicoding that I worked on independently. This project is a part of the requirements for graduating from the Machine Learning Developer class that I attended. The dataset used was obtained from the Dicoding platform.

A link to the [data](https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip) used in the project.

## Table of  Contents
- [Background](#background)
- [Conclusion](#conclusion)
- [Maintainers](#maintainers)

## Background
### Project approach:
1. Objectives
2. Methodology
3. Expected Outcomes

### 1. Objectives
The primary objectives of this project are:

1. Gather and preprocess a comprehensive dataset of hand images representing rock, paper, and scissors gestures, ensuring a diverse range of hand shapes, sizes, and skin tones.
2. Design and train a convolutional neural network (CNN) tailored for image classification to accurately distinguish between the three hand image categories.
3. Assess the model's accuracy and performance using a dedicated validation dataset, employing metrics of accuracy and loss on both training and validation data.

### 2. Methodology

- Data Collection and Preprocessing
- Model Development
- Model Evaluation

### 3. Expected Outcomes

An image classification model that can accurately distinguish 3 categories of images: rock, paper, and scissors.


## Conclusion
From this **rock-paper-scissors image classification** project, I gained a deeper understanding of machine learning, image processing, and techniques related to classification tasks

## Maintainers
[@velyncodes](https://github.com/velyncodes)

©️ Zevanna Vangelyn (Velyn)
